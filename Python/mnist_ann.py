# -*- coding: utf-8 -*-
"""MNIST_ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A4jT4A0H4UWUo9IFpUibceZZ-oGRCVd8
"""

from google.colab import drive
drive.mount('/content/drive')
#download file
!gdown 1F_-g56Dg9cPxcqsWvHFCQsuFWXOapP2G


# install dependencies
!pip install scipy numpy
!pip install cvnn
!pip install tensorflow-addons

# import all dependencies
import scipy.io
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import cvnn.layers as complex_layers
import numpy as np
from cvnn import losses
from cvnn import metrics
from pdb import set_trace
from importlib import reload
import os
import tensorflow
from matplotlib import pyplot as plt
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.python.client import device_lib
import time

# Load 2D MNIST dataset
#MNIST_2D_RAW = scipy.io.loadmat('/content/2d_mnist_data.mat')
MNIST_2D_RAW = scipy.io.loadmat(r'E:/...Your Directory.../2d_mnist_data.mat')
MNIST_2D_Train_images = MNIST_2D_RAW['train_images']
MNIST_2D_Test_images = MNIST_2D_RAW['test_images']
print(MNIST_2D_Train_images.shape)

#mnist_label_mat = scipy.io.loadmat('/content/mnist_train_lbel.mat')
mnist_train_label_raw = MNIST_2D_RAW['train_labels']
mnist_train_label_rehaped = np.reshape(mnist_train_label_raw, (60000))
mnist_train_label = to_categorical(mnist_train_label_rehaped, 10)
print(mnist_train_label.shape)

mnist_test_label_raw = MNIST_2D_RAW['test_labels']
mnist_test_label_rehaped = np.reshape(mnist_test_label_raw, (10000))
mnist_test_label = to_categorical(mnist_train_label_rehaped, 10)

MNIST_2D_Train_images[1]
x_train_flattened = MNIST_2D_Train_images.reshape(MNIST_2D_Train_images.shape[0], -1)
x_test_flattened = MNIST_2D_Test_images.reshape(MNIST_2D_Test_images.shape[0], -1)

x_train_normalized = x_train_flattened / 255.0
x_test_normalized = x_test_flattened / 255.0
x_train_normalized.shape

def mlp_rv_function(train_images, train_labels, val_images, val_labels, epochs=10):
  tf.random.set_seed(1)
  model_RV_ANN = models.Sequential()
  model_RV_ANN.add(tf.keras.Input(shape=(784,)))
  model_RV_ANN.add(tf.keras.layers.Dense(20, activation='relu'))
  model_RV_ANN.add(tf.keras.layers.Dense(10, activation='softmax'))

  model_RV_ANN.compile(optimizer='Adam',
                  loss=tf.keras.losses.BinaryCrossentropy(),
                  metrics=tf.keras.metrics.CategoricalAccuracy())

  start_time = time.time()
  history = model_RV_ANN.fit(train_images, train_labels, epochs=epochs, validation_data=(val_images, val_labels),batch_size=32)
  end_time = time.time()
  training_duration = end_time - start_time
  return history, model_RV_ANN, training_duration

train_images, val_images, train_labels, val_labels = train_test_split(x_train_normalized, mnist_train_label, test_size=0.02, random_state=42)
epochs=50
[history, model_RV_ANN, duration] = mlp_rv_function(train_images, train_labels, val_images, val_labels, epochs)
print(f"Training took {duration:.2f} seconds.")
model_RV_ANN.save_weights('model_weights_RV_ANN.h5')

# Define Model for test data

acti = 'relu'

model_RV_2 = models.Sequential()
model_RV_2.add(tf.keras.Input(shape=(784,)))                    # Always use ComplexInput at the start
model_RV_2.add(tf.keras.layers.Dense(20, activation='relu'))
model_RV_2.add(tf.keras.layers.Dense(10, activation='softmax'))

model_RV_2.load_weights('model_weights_RV_ANN.h5')
model_RV_2.summary()

import time
#Data Processing

#get int label
test_mnist_label_mat = scipy.io.loadmat('/content/mnist_test_label.mat')
mnist_test_label_raw = test_mnist_label_mat['test_labels']
gt_int_list = list(np.reshape(mnist_test_label_raw, (10000)))
print(type(gt_int_list))
print(len(gt_int_list))
print(type(gt_int_list[0]))

start_time = time.time()
batch_size = 124  # or whatever batch size you prefer
predictions = model_RV_2.predict(x_test_normalized, batch_size=batch_size)
end_time = time.time()
inference_duration = end_time - start_time
print(f"Inference took {inference_duration:.2f} seconds.")


pred_int_list = []
for each_pred in predictions:
  temp_pred_int = np.argmax(np.abs(each_pred))
  pred_int_list.append(temp_pred_int)

print(len(pred_int_list))


# Precision plot
from sklearn.metrics import classification_report

target_names = list(set(gt_int_list)).sort()
print(classification_report(gt_int_list, pred_int_list, labels=target_names))


# Confusion matrix plot
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(gt_int_list, pred_int_list, labels=target_names)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)
cmap = 'Blues'

# Plot the confusion matrix with the specified colormap
disp.plot(cmap=cmap)
plt.savefig("ConfusionMatrix_MNIST_RAW_ANN_20N.png", dpi=600)

weight_object_list = model_RV_ANN.get_weights()
layer_1_weights = weight_object_list[0]
layer_1_bias = weight_object_list[1]

layer_2_weights = weight_object_list[2]
layer_2_bias = weight_object_list[3]
weight_object_list[3].shape


def relu(x):
    # Element-wise ReLU operation
    return np.maximum(0, x)

def curt_relu(x):
    # Apply ReLU to both real and imaginary parts separately
    real_part_relu = relu(x.real)
    imag_part_relu = relu(x.imag)

    # Combine the real and imaginary parts to form the complex result
    result = real_part_relu + 1j * imag_part_relu

    return result

def complex_softmax(x):
    # Calculate exp(x)
    exp_x = np.exp(x)

    # Calculate the sum of exp(x) along the specified axis (sum over all elements)
    sum_exp_x = np.sum(exp_x)

    # Calculate the softmax probabilities for each element
    softmax_probabilities = exp_x / sum_exp_x

    return softmax_probabilities

def softmax(x):
    # Ensure numerical stability by subtracting the maximum value
    # from all elements before exponentiation.
    e_x = np.exp(x - np.max(x))
    return e_x / e_x.sum()


index_number = 0
input_layer_weightedSum = np.dot(x_test_normalized[index_number],layer_1_weights)+layer_1_bias # z1 = x*w1+b1

Layer_1_output = relu(input_layer_weightedSum) # Relu Activation Function y1=p(z1)

hidden_layer_weightedSum = np.dot(Layer_1_output,layer_2_weights)+layer_2_bias # z2 = y1*w2+b2


Layer_hidden_output = softmax(hidden_layer_weightedSum)  # Softmax Activation # y2 = p(z2)
final_ouput =  np.argmax(Layer_hidden_output)  #


print("Scratch: " + str(final_ouput))
temp_pred_complex = model_RV_ANN.predict(np.reshape(x_test_normalized[index_number], (1,784)))
temp_pred_int = np.argmax(np.abs(temp_pred_complex[0]))
print("Built-in: "+ str(temp_pred_int))
print("No Softmax:" + str(np.argmax(hidden_layer_weightedSum)))

ANN_weight_1 = (layer_1_weights.T)
flattened_array = ANN_weight_1.flatten()
np.savetxt('ANN_RAW_MNIST_weight_1.txt', flattened_array, delimiter=',', newline=',')

ANN_weight_2 = (layer_2_weights.T)
flattened_array = ANN_weight_2.flatten()
np.savetxt('ANN_RAW_MNIST_weight_2.txt', flattened_array, delimiter=',', newline=',')

ANN_layer_1_bias = (layer_1_bias)
flattened_array = ANN_layer_1_bias.flatten()
np.savetxt('ANN_RAW_MNIST_layer_1_bias.txt', flattened_array, delimiter=',', newline=',')

ANN_layer_2_bias = (layer_2_bias)
flattened_array = ANN_layer_2_bias.flatten()
np.savetxt('ANN_RAW_MNIST_layer_2_bias.txt', flattened_array, delimiter=',', newline=',')

RV_mnist_test_0_30 = (x_test_normalized[0:30])
flattened_array = RV_mnist_test_0_30.flatten()
np.savetxt('ANN_RAW_MNIST_test_0_10.txt', flattened_array, delimiter=',', newline=',')
RV_mnist_test_0_30.shape

# Confusion matrix plot
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(gt_int_list, pred_int_list, labels=target_names)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)
cmap = 'Blues'

# Plot the confusion matrix with the specified colormap
disp.plot(cmap=cmap)